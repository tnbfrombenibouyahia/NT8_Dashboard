import streamlit as st
import pandas as pd
import json
import plotly.graph_objects as go
import os
from datetime import datetime, timedelta, date
import calendar
import datetime as dt
import yfinance as yf
import plotly.graph_objects as go
import numpy as np

import streamlit_authenticator as stauth

# Vos modules perso
from data_cleaner import load_and_clean_csv, update_historical_data
from gdrive_backup import get_drive_service_from_secrets, restore_user_data, backup_user_data
from utils_visuals import (
    plot_equity_curve,
    plot_drawdown_curve,
    plot_gain_loss_pie,
    plot_asset_distribution,
    plot_avg_duration_per_day,
    plot_return_vs_duration,
    compute_stats_dict,
    plot_pnl_by_hour,
    plot_pnl_by_day_of_week,
    plot_daily_pnl,
    plot_daily_drawdown,
    plot_histogram_mae_mfe_etd,
    plot_scatter_mfe_vs_profit,
    plot_pct_mfe_captured,
    plot_pct_mae_vs_etd,
    plot_scatter_mfe_captured,
    plot_heatmap_mfe_mae,
    plot_mfe_vs_time,
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration de la page Streamlit
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ğŸ¥· Trading Dashboard",
    layout="wide",
    page_icon="ğŸ¥·",
    initial_sidebar_state="expanded"
)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Liste d'utilisateurs de test : noms, emails (usernames) et mots de passe hashÃ©s
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
names = ["ThÃ©o NaÃ¯m BENHELLAL", "Alexis DURIN"]
usernames = ["theonaimben@gmail.com", "alexisdurin@gmail.com"]

hashed_passwords = [
    '$2b$12$diwoxjm5v8dciC0/UUJXLuTPPFx5UrfiwhhgQwNVZYi4lZTwQJI0O',
    '$2b$12$/DFXDjyc2sEGqPXCweJqduJcxE6tSlvk1MnAYVIJErU1/ELgM7b9C'
]

credentials = {
    "usernames": {
        "theonaimben@gmail.com": {
            "name": "ThÃ©o NaÃ¯m BENHELLAL",
            "password": "$2b$12$diwoxjm5v8dciC0/UUJXLuTPPFx5UrfiwhhgQwNVZYi4lZTwQJI0O"
        },
        "durinalexis@gmail.com": {
            "name": "Alexis DURIN",
            "password": "$2b$12$83LWaR64YJwamdbNj/rE8u1V9EES1tnuIulQEKfneQl95ILZStMy6"
        }
    }
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Authentification avec streamlit-authenticator
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
authenticator = stauth.Authenticate(
    credentials,
    "dashboard_cookie",     # nom du cookie
    "abcdef",               # clÃ© de hachage
    cookie_expiry_days=7    # durÃ©e de validitÃ© (jours)
)

login_result = authenticator.login("Login", "main")

try:
    name, authentication_status, username = login_result
except TypeError:
    name = authentication_status = username = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gestion de lâ€™Ã©tat de connexion
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if authentication_status is False:
    st.error("Nom dâ€™utilisateur ou mot de passe invalide âŒ")
    st.stop()

elif authentication_status is None:
    st.warning("Veuillez entrer vos identifiants ğŸ”")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Si on arrive ici, lâ€™utilisateur est authentifiÃ©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
authenticator.logout("ğŸšª Se dÃ©connecter", "sidebar")
st.sidebar.success(f"ConnectÃ© en tant que {name}")
st.success(f"Bienvenue {name} ğŸ‘‹")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ” Restauration automatique Google Drive si donnÃ©es manquantes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
user_data_dir = os.path.join("data", username)  
data_file = os.path.join(user_data_dir, "trades_historique.csv")
journal_file = os.path.join(user_data_dir, "journal_notes.json")

try:
    drive_service = get_drive_service_from_secrets()
    restore_user_data(
        drive_service=drive_service,
        local_data_dir=user_data_dir,
        backup_folder_name="Streamlit_Backup",
        username=username
    )
    
    print("âœ… Restauration automatique terminÃ©e.")
except Exception as e:
    print(f"âŒ Erreur de restauration automatique : {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DÃ©finition des chemins de fichiers pour CET utilisateur
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
user_data_dir = os.path.join("data", username)  
os.makedirs(user_data_dir, exist_ok=True)

data_file = os.path.join(user_data_dir, "trades_historique.csv")
journal_file = os.path.join(user_data_dir, "journal_notes.json")

# Initialisation si inexistant
if not os.path.exists(data_file):
    pd.DataFrame(columns=[
        "Entry time", "Exit time", "Instrument", "Market pos.",
        "Entry price", "Exit price", "Qty", "Profit",
        "MAE", "MFE", "ETD"
    ]).to_csv(data_file, index=False)

if not os.path.exists(journal_file):
    with open(journal_file, "w") as f:
        json.dump({}, f)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Lecture de l'historique
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    if os.path.exists(data_file):
        df_histo = pd.read_csv(data_file, parse_dates=["Entry time", "Exit time"])
        df_histo = df_histo[pd.notnull(df_histo["Entry time"])]
        df_histo["Instrument"] = df_histo["Instrument"].str.extract(r"^([A-Z]+)")
    else:
        st.warning("Aucun fichier d'historique trouvÃ© pour cet utilisateur.")
        st.stop()
except Exception as e:
    st.error(f"Erreur lors du chargement du fichier historique : {e}")
    st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# UI Style global
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
    <style>
        html, body, [class*="css"]  {
            font-family: 'Inter', sans-serif;
        }
        .block-container {
            padding-top: 2rem;
        }
    </style>
""", unsafe_allow_html=True)

st.title("ğŸ¥· Dashboard NinjaTrader")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Section Filtres
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.header("ğŸ‘€ Filtres")
col_f1, col_f2, col_f3 = st.columns(3)

with col_f1:
    instruments = df_histo["Instrument"].unique().tolist()
    instrument = st.selectbox("ğŸ‡ºğŸ‡¸ Instrument", ["Tous"] + instruments)

with col_f2:
    directions = df_histo["Market pos."].unique().tolist()
    direction = st.selectbox("ğŸ“Œ Positions", ["Tous"] + directions)

with col_f3:
    if not df_histo["Entry time"].dropna().empty:
        default_start = pd.to_datetime(df_histo["Entry time"]).min().date()
        default_end = pd.to_datetime(df_histo["Entry time"]).max().date()
    else:
        default_start = date.today() - timedelta(days=30)
        default_end = date.today()

    date_range = st.date_input("ğŸ“… PÃ©riode", (default_start, default_end))

# Application des filtres
df_filtered = df_histo.copy()

if instrument != "Tous":
    df_filtered = df_filtered[df_filtered["Instrument"] == instrument]
if direction != "Tous":
    df_filtered = df_filtered[df_filtered["Market pos."] == direction]

if isinstance(date_range, tuple) and len(date_range) == 2:
    start_date, end_date = date_range
elif isinstance(date_range, date):
    start_date = end_date = date_range
else:
    start_date = df_histo["Entry time"].min().date()
    end_date = df_histo["Entry time"].max().date()

if not df_filtered.empty and pd.api.types.is_datetime64_any_dtype(df_filtered["Entry time"]):
    df_filtered = df_filtered[
        (df_filtered["Entry time"].dt.date >= start_date) &
        (df_filtered["Entry time"].dt.date <= end_date)
    ]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar : Upload CSV
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.markdown("## ğŸ“‚ Import Zone")
uploaded_file = st.sidebar.file_uploader("", type=["csv"])

if uploaded_file:
    # Chargement et nettoyage
    df_new = load_and_clean_csv(uploaded_file)

    # Fusion avec l'historique propre Ã  l'utilisateur
    user_csv_path = os.path.join(user_data_dir, "trades_historique.csv")
    df_combined, new_count = update_historical_data(df_new, user_csv_path)

    # Logs console (utile sur Streamlit Cloud)
    print(f"[UPLOAD] âœ… Fichier importÃ© par : {username}")
    print(f"[UPLOAD] â• {new_count} nouveaux trades ajoutÃ©s.")
    print(f"[UPLOAD] ğŸ“ Chemin : {user_csv_path}")

    # Message utilisateur
    st.sidebar.success(f"{new_count} nouveaux trades ajoutÃ©s Ã  l'historique. Recharge la page pour voir les changements.")
    st.sidebar.info(f"ğŸ“ DonnÃ©es sauvegardÃ©es dans : `{user_csv_path}`")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sidebar : Journal de sÃ©ance
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.sidebar.markdown("---")
st.sidebar.markdown("## ğŸ““ Journal de sÃ©ance")

image_dir = os.path.join(user_data_dir, "journal_images")
os.makedirs(image_dir, exist_ok=True)

with open(journal_file, "r") as f:
    journal = json.load(f)

# Convertir si ancien format (v = string)
for k, v in journal.items():
    if isinstance(v, str):
        journal[k] = {"text": v, "images": []}

aujourd_hui = pd.to_datetime("today").normalize()
cle_du_jour = str(aujourd_hui)

if cle_du_jour not in journal:
    st.sidebar.warning("ğŸ“ Tu nâ€™as pas encore rempli ta note de trading aujourdâ€™hui !")

note = st.sidebar.text_area(
    "âœï¸ Ta note du jour",
    value=journal.get(cle_du_jour, {}).get("text", ""),
    height=150
)
images = st.sidebar.file_uploader("ğŸ“¸ Ajouter des captures", type=["png", "jpg", "jpeg"], accept_multiple_files=True)

if st.sidebar.button("ğŸ’¾ Sauvegarder ma note", use_container_width=True):
    saved_images = []
    for img in images:
        img_path = os.path.join(image_dir, f"{cle_du_jour}_{img.name}")
        with open(img_path, "wb") as f:
            f.write(img.getbuffer())
        saved_images.append(img_path)

    journal[cle_du_jour] = {"text": note, "images": saved_images}
    with open(journal_file, "w") as f:
        json.dump(journal, f)
    st.sidebar.success("Note enregistrÃ©e avec succÃ¨s ğŸ‰")

        # Sauvegarde automatique sur Google Drive
    try:
        from gdrive_backup import get_drive_service, backup_user_data
        json_key_path = "dashboarding-tn8-7a67de160a56.json"
        drive_service = get_drive_service(json_key_path)
        backup_user_data(
            drive_service=drive_service,
            local_data_dir=user_data_dir,
            backup_folder_name="Streamlit_Backup",
            json_key_path=json_key_path,
            username=username
        )
        st.sidebar.success("ğŸª£ Sauvegarde Drive terminÃ©e âœ…")
    except Exception as e:
        st.sidebar.error(f"âŒ Erreur de sauvegarde Drive : {e}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Calcul de colonnes supplÃ©mentaires
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if not df_filtered.empty:
    df_filtered["DurÃ©e (min)"] = (
        df_filtered["Exit time"] - df_filtered["Entry time"]
    ).dt.total_seconds() / 60
    df_filtered["Rendement (%)"] = (
        df_filtered["Profit"] / (df_filtered["Entry price"] * df_filtered["Qty"])
    ) * 100

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Profit / Risk Zone
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("## ğŸ° Profit / Risk Zone")
col1, col2 = st.columns(2)

with col1:
    st.plotly_chart(plot_equity_curve(df_filtered), use_container_width=True, key="equity")

with col2:
    st.plotly_chart(plot_drawdown_curve(df_filtered), use_container_width=True, key='drawdown')

col_daily1, col_daily2 = st.columns(2)
with col_daily1:
    st.plotly_chart(plot_daily_pnl(df_filtered), use_container_width=True, key="daily_pnl")
with col_daily2:
    st.plotly_chart(plot_daily_drawdown(df_filtered), use_container_width=True, key="daily_drawdown")

# Statistiques clÃ©s
stats = compute_stats_dict(df_filtered)

def render_stat_card(title, value, emoji):
    return f"""
    <div style="background-color:#0e1117;padding:18px;border-radius:12px;margin:10px;
    text-align:center;box-shadow:0 0 10px rgba(0,0,0,0.3);min-width:160px;">
        <div style="font-size:32px;">{emoji}</div>
        <div style="font-weight:500;font-size:14px;color:#ccc;margin-top:4px;">{title}</div>
        <div style="font-size:26px;font-weight:bold;margin-top:2px;color:#fff;">{value}</div>
    </div>
    """

st.markdown("")
cols1 = st.columns(4)
cols1[0].markdown(render_stat_card("Meilleur Trade", f"${stats['best_trade']}", "ğŸ«"), unsafe_allow_html=True)
cols1[1].markdown(render_stat_card("Pire Trade", f"${stats['worst_trade']}", "ğŸŒ¶ï¸"), unsafe_allow_html=True)
cols1[2].markdown(render_stat_card("Gain Moyen", f"${stats['avg_gain']}", "ğŸ“ˆ"), unsafe_allow_html=True)
cols1[3].markdown(render_stat_card("Perte Moyenne", f"${stats['avg_loss']}", "ğŸ“‰"), unsafe_allow_html=True)

cols2 = st.columns(4)
cols2[0].markdown(render_stat_card("Total Trades", stats["total_trades"], "ğŸ’½"), unsafe_allow_html=True)
cols2[1].markdown(render_stat_card("Winrate", f"{stats['winrate']}%", "ğŸ²"), unsafe_allow_html=True)
cols2[2].markdown(render_stat_card("Sharpe Ratio", stats["sharpe_ratio"], "ğŸŒŠ"), unsafe_allow_html=True)
cols2[3].markdown(render_stat_card("Profit Factor", stats["profit_factor"], "ğŸ§˜â€â™‚ï¸"), unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Timing Zone
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.markdown("## ğŸ„â€â™‚ï¸ Timing Zone")

col1b, col2b = st.columns(2)
with col1b:
    st.plotly_chart(plot_avg_duration_per_day(df_filtered), use_container_width=True, key="avg_duration")
with col2b:
    st.plotly_chart(plot_return_vs_duration(df_filtered), use_container_width=True, key="return_duration")

col3, col4 = st.columns(2)
with col3:
    st.plotly_chart(plot_pnl_by_day_of_week(df_filtered), use_container_width=True, key="pnl_day")
with col4:
    st.plotly_chart(plot_pnl_by_hour(df_filtered), use_container_width=True, key="pnl_hour")

# Statistiques Timing
st.markdown("---")
st.subheader("ğŸ“Š Statistiques Timing")

if all(col in df_filtered.columns for col in ["DurÃ©e (min)", "Entry time", "Profit"]):
    avg_duration = round(df_filtered["DurÃ©e (min)"].mean(), 2)
    active_days = df_filtered["Entry time"].dt.date.nunique()

    try:
        best_day = df_filtered.groupby(df_filtered["Entry time"].dt.day_name())["Profit"].sum().idxmax()
    except ValueError:
        best_day = "N/A"

    try:
        worst_day = df_filtered.groupby(df_filtered["Entry time"].dt.day_name())["Profit"].sum().idxmin()
    except ValueError:
        worst_day = "N/A"

    try:
        best_hour = df_filtered.groupby(df_filtered["Entry time"].dt.hour)["Profit"].sum().idxmax()
    except ValueError:
        best_hour = "N/A"

    try:
        worst_hour = df_filtered.groupby(df_filtered["Entry time"].dt.hour)["Profit"].sum().idxmin()
    except ValueError:
        worst_hour = "N/A"
else:
    avg_duration = 0
    active_days = 0
    best_day = worst_day = best_hour = worst_hour = "N/A"

cols_timing = st.columns(3)
cols_timing[0].markdown(render_stat_card("DurÃ©e Moyenne", f"{avg_duration} min", "â±ï¸"), unsafe_allow_html=True)
cols_timing[1].markdown(render_stat_card("Jours Actifs", active_days, "ğŸ“†"), unsafe_allow_html=True)
cols_timing[2].markdown(render_stat_card("Heure la + rentable", f"{best_hour}h" if best_hour != "N/A" else "N/A", "ğŸ¬"), unsafe_allow_html=True)

cols_timing2 = st.columns(3)
cols_timing2[0].markdown(render_stat_card("Jour le + rentable", best_day, "ğŸ“ˆ"), unsafe_allow_html=True)
cols_timing2[1].markdown(render_stat_card("Jour le - performant", worst_day, "ğŸ“‰"), unsafe_allow_html=True)
cols_timing2[2].markdown(render_stat_card("Heure la - rentable", f"{worst_hour}h" if worst_hour != "N/A" else "N/A", "ğŸš¹"), unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Distribution
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.markdown("## ğŸ§€ Distribution")

col5, col6 = st.columns(2)
with col5:
    st.plotly_chart(plot_asset_distribution(df_filtered), use_container_width=True, key="asset_distr")
with col6:
    st.plotly_chart(plot_gain_loss_pie(df_filtered), use_container_width=True, key="gain_loss")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Optimisation des targets
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.markdown("## ğŸ‘¨â€ğŸ”¬ Optimisation des targets")

st.plotly_chart(plot_histogram_mae_mfe_etd(df_filtered), use_container_width=True, key="hist_mfe")
st.plotly_chart(plot_scatter_mfe_vs_profit(df_filtered), use_container_width=True, key="mfe_profit")

mae_mean = round(df_filtered["MAE"].mean(), 2) if "MAE" in df_filtered else 0
mfe_mean = round(df_filtered["MFE"].mean(), 2) if "MFE" in df_filtered else 0
etd_mean = round(df_filtered["ETD"].mean(), 2) if "ETD" in df_filtered else 0
mfe_mae_ratio = round(mfe_mean / mae_mean, 2) if mae_mean != 0 else 0

cols_targets = st.columns(4)
cols_targets[0].markdown(render_stat_card("MAE moyen", f"${mae_mean}", "ğŸ§¨"), unsafe_allow_html=True)
cols_targets[1].markdown(render_stat_card("MFE moyen", f"${mfe_mean}", "ğŸ¾"), unsafe_allow_html=True)
cols_targets[2].markdown(render_stat_card("ETD moyen", f"${etd_mean}", "ğŸ¤º"), unsafe_allow_html=True)
cols_targets[3].markdown(render_stat_card("Ratio MFE/MAE", mfe_mae_ratio, "ğŸ§‘â€âš–ï¸"), unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ¯ Analyse des sorties
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.header("ğŸ¯ Analyse des sorties")

with st.expander("ğŸ§  % du MFE captÃ© par trade", expanded=True):
    st.plotly_chart(plot_pct_mfe_captured(df_filtered), use_container_width=True)
    st.caption("""
    Ce graphique indique le pourcentage du mouvement favorable (MFE) captÃ© par chaque trade.

    Exemples :
    - 100% = tu as sorti au plus haut du mouvement favorable.
    - 50% = tu as captÃ© la moitiÃ© du potentiel avant de sortir.
    - 0% = tu es sorti au break-even alors que le trade avait du potentiel.

    ğŸ‘‰ Objectif : te rapprocher de la droite, en captant une part croissante du mouvement,
    sans augmenter ton risque. Un bon trader capture efficacement sans rester trop longtemps.
    """)

    # Calculs pour le commentaire interactif
    mfe_series = (df_filtered["Profit"] / df_filtered["MFE"] * 100).replace([np.inf, -np.inf], np.nan).dropna()
    mfe_series = mfe_series[(mfe_series >= 0) & (mfe_series <= 300)]

    q1 = mfe_series.quantile(0.25)
    mean = mfe_series.mean()
    median = mfe_series.median()
    q3 = mfe_series.quantile(0.75)

    st.markdown(f"""
    ğŸ’¬ **Analyse des sorties :**

    - **Q1 : {q1:.1f}%** â†’ 25% des trades ont captÃ© **moins de {q1:.1f}%** du mouvement favorable. Cela peut indiquer des sorties trop prÃ©coces ou un manque de confiance.
    - **Moyenne : {mean:.1f}%** â†’ En moyenne, tu captures **{mean:.1f}%** du potentiel. C'est ton niveau global d'efficacitÃ© de sortie.
    - **MÃ©diane : {median:.1f}%** â†’ 50% des trades capturent plus de **{median:.1f}%**, l'autre moitiÃ© moins. Une mÃ©diane supÃ©rieure Ã  70% est dÃ©jÃ  **trÃ¨s solide**.
    - **Q3 : {q3:.1f}%** â†’ 25% des trades les plus efficaces captent plus de **{q3:.1f}%**, ce sont tes meilleures sorties.

    ğŸ‘‰ **Objectif** : faire monter la mÃ©diane et la moyenne vers Q3, tout en gardant un bon ratio gain/risque. Une courbe Ã©talÃ©e avec un Q1 trÃ¨s bas peut indiquer des trades gÃ¢chÃ©s malgrÃ© du potentiel.
    """)
    

with st.expander("ğŸ§  % du MAE encaissÃ© sur profit rÃ©alisÃ©", expanded=True):
    st.plotly_chart(plot_pct_mae_vs_etd(df_filtered), use_container_width=True)
    st.caption("""
    Ce graphique mesure combien de drawdown (MAE) tu as encaissÃ© **avant de finir en profit**.

    Exemples :
    - 20% = tu es restÃ© assez proche de ton prix dâ€™entrÃ©e avant de sortir gagnant.
    - 100% = tu as encaissÃ© un drawdown aussi grand que ton profit final.
    - >100% = tu Ã©tais bien dans le rouge avant de finir dans le vert (stress Ã©levÃ©).

    ğŸ‘‰ Objectif : rÃ©duire ces valeurs. Plus tu es capable de sortir gagnant sans gros stress,
    plus ton trading est propre et maÃ®trisÃ©.
    """)

    # Calculs pour analyse interactive du MAE
    mae_series = (df_filtered["MAE"] / df_filtered["ETD"] * 100).replace([np.inf, -np.inf], np.nan).dropna()
    mae_series = mae_series[(mae_series >= 0) & (mae_series <= 300)]

    q1_mae = mae_series.quantile(0.25)
    mean_mae = mae_series.mean()
    median_mae = mae_series.median()
    q3_mae = mae_series.quantile(0.75)

    st.markdown(f"""
    ğŸ’¬ **Analyse du stress (MAE) encaissÃ© avant profit :**

    - **Q1 : {q1_mae:.1f}%** â†’ 25% des trades gagnants ont encaissÃ© **moins de {q1_mae:.1f}%** de drawdown avant de finir en profit. Cela traduit une bonne prÃ©cision ou un timing propre.
    - **Moyenne : {mean_mae:.1f}%** â†’ En moyenne, tu encaisses **{mean_mae:.1f}%** de drawdown par rapport Ã  ton gain. Moins câ€™est Ã©levÃ©, plus ton trade est stable.
    - **MÃ©diane : {median_mae:.1f}%** â†’ 50% des trades ont encaissÃ© moins de **{median_mae:.1f}%**, câ€™est ton niveau mÃ©dian de stress avant gain.
    - **Q3 : {q3_mae:.1f}%** â†’ 25% des trades gagnants ont encaissÃ© plus de **{q3_mae:.1f}%** de drawdown : câ€™est ton quart le plus stressant.

    ğŸ‘‰ **Objectif** : faire baisser la moyenne et la mÃ©diane pour un trading plus propre et maÃ®trisÃ©. Une mÃ©diane < 50% indique que tu restes souvent proche de ton point dâ€™entrÃ©e avant de sortir gagnant, ce qui est excellent.
    """)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Liste des trades filtrÃ©s
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.subheader("ğŸ“‹ Liste des trades")

st.dataframe(df_filtered.sort_values("Entry time", ascending=False), use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DerniÃ¨re Session (navigation sur les notes)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.subheader("ğŸï¸ DerniÃ¨re Session")

dates_dispo = sorted(journal.keys())
if len(dates_dispo) >= 1:
    if "note_index" not in st.session_state:
        st.session_state.note_index = len(dates_dispo) - 1

    colA, colB, colC = st.columns([1,6,1])
    with colA:
        if st.button("â¬…ï¸", use_container_width=True) and st.session_state.note_index > 0:
            st.session_state.note_index -= 1

    selected_date = dates_dispo[st.session_state.note_index]
    selected_note = journal[selected_date]

    with colB:
        st.markdown(
            f"<div style='text-align: center; font-size: 26px; padding-top: 6px;'>ğŸ“… {selected_date.split(' ')[0]}</div>",
            unsafe_allow_html=True
        )

    with colC:
        if st.button("â¡ï¸", use_container_width=True) and st.session_state.note_index < len(dates_dispo) - 1:
            st.session_state.note_index += 1

    st.markdown(f"> {selected_note['text']}")

    for path in selected_note.get("images", []):
        st.image(path, use_container_width=True)

else:
    st.info("ğŸ‘‰ Ajoute au moins une note pour naviguer.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Listing complet de toutes les sessions enregistrÃ©es
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.subheader("ğŸ§¾ Listing de toutes les sessions enregistrÃ©es")

records = []
for d in sorted(journal.keys(), reverse=True):
    note = journal[d]
    preview_text = note["text"][:120] + ("..." if len(note["text"]) > 120 else "")
    records.append({
        "Date": d.split(" ")[0],
        "RÃ©sumÃ©": preview_text,
        "Nb images": len(note.get("images", [])),
        "ClÃ©": d
    })

df_notes = pd.DataFrame(records)

if not df_notes.empty:
    for idx, row in df_notes.iterrows():
        with st.expander(f"ğŸ“… {row['Date']} â€” {row['RÃ©sumÃ©']}"):
            st.markdown(f"### ğŸ—’ï¸ Note du {row['Date']}")
            st.markdown(journal[row["ClÃ©"]]["text"])
            for path in journal[row["ClÃ©"]].get("images", []):
                st.image(path, use_container_width=True)
else:
    st.info("Aucune note Ã  afficher.")

from gdrive_backup import get_drive_service_from_secrets, backup_user_data

st.markdown("---")
st.subheader("â˜ï¸ Sauvegarde Google Drive")

if st.button("ğŸ” Sauvegarder mes donnÃ©es sur Drive", use_container_width=True):
    try:
        drive_service = get_drive_service_from_secrets()
        backup_user_data(
            drive_service=drive_service,
            local_data_dir=user_data_dir,
            backup_folder_name="Streamlit_Backup",
            username=username
        )
        st.success("ğŸ“¦ DonnÃ©es sauvegardÃ©es sur Google Drive avec succÃ¨s !")
    except Exception as e:
        st.error(f"âŒ Erreur lors de la sauvegarde : {e}")
